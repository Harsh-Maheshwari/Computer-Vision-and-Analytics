{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import os\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Test and Train Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381 164\n"
     ]
    }
   ],
   "source": [
    "files_train = 0\n",
    "files_validation = 0\n",
    "\n",
    "cwd = os.getcwd()\n",
    "folder = 'train_data/train'\n",
    "for sub_folder in os.listdir(folder):\n",
    "    path, dirs, files = next(os.walk(os.path.join(folder,sub_folder)))\n",
    "    files_train += len(files)\n",
    "\n",
    "\n",
    "folder = 'train_data/test'\n",
    "for sub_folder in os.listdir(folder):\n",
    "    path, dirs, files = next(os.walk(os.path.join(folder,sub_folder)))\n",
    "    files_validation += len(files)\n",
    "\n",
    "print(files_train,files_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set key parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 48, 48\n",
    "train_data_dir = \"train_data/train\"\n",
    "validation_data_dir = \"train_data/test\"\n",
    "nb_train_samples = files_train\n",
    "nb_validation_samples = files_validation\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build model on top of a trained VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:10]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "# x = Dense(512, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(256, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model\n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model\n",
    "model_final.compile(loss = \"categorical_crossentropy\", \n",
    "                    optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), \n",
    "                    metrics=[\"accuracy\"]) # See learning rate is very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 images belonging to 2 classes.\n",
      "Found 164 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initiate the train and test generators with data Augumentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.1,\n",
    "width_shift_range = 0.1,\n",
    "height_shift_range=0.1,\n",
    "rotation_range=5)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.1,\n",
    "width_shift_range = 0.1,\n",
    "height_shift_range=0.1,\n",
    "rotation_range=5)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions\n",
    "checkpoint = ModelCheckpoint(\"car1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  if __name__ == '__main__':\n",
      "/home/harsh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=15, validation_data=<keras.pre..., callbacks=[<keras.ca..., steps_per_epoch=11, validation_steps=164)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.6504 - accuracy: 0.5931 - val_loss: 0.3645 - val_accuracy: 0.7698\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "/home/harsh/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 46s 4s/step - loss: 0.3850 - accuracy: 0.7727 - val_loss: 0.4273 - val_accuracy: 0.8306\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 46s 4s/step - loss: 0.2705 - accuracy: 0.9046 - val_loss: 0.2780 - val_accuracy: 0.9169\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 46s 4s/step - loss: 0.2101 - accuracy: 0.9375 - val_loss: 0.2839 - val_accuracy: 0.9107\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 45s 4s/step - loss: 0.1382 - accuracy: 0.9566 - val_loss: 0.1608 - val_accuracy: 0.9143\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.1462 - accuracy: 0.9460 - val_loss: 0.1218 - val_accuracy: 0.9243\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 45s 4s/step - loss: 0.1010 - accuracy: 0.9685 - val_loss: 0.0923 - val_accuracy: 0.9163\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 45s 4s/step - loss: 0.1312 - accuracy: 0.9624 - val_loss: 0.1793 - val_accuracy: 0.9223\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.1113 - accuracy: 0.9659 - val_loss: 0.0294 - val_accuracy: 0.9247\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 46s 4s/step - loss: 0.0937 - accuracy: 0.9682 - val_loss: 0.0648 - val_accuracy: 0.9250\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 45s 4s/step - loss: 0.0789 - accuracy: 0.9773 - val_loss: 0.0261 - val_accuracy: 0.9288\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.0813 - accuracy: 0.9799 - val_loss: 0.0468 - val_accuracy: 0.9297\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.0734 - accuracy: 0.9799 - val_loss: 0.2801 - val_accuracy: 0.9294\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.0831 - accuracy: 0.9713 - val_loss: 0.0961 - val_accuracy: 0.9305\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.0710 - accuracy: 0.9799 - val_loss: 0.0035 - val_accuracy: 0.9294\n"
     ]
    }
   ],
   "source": [
    "### Start training!\n",
    "\n",
    "history_object = model_final.fit_generator(\n",
    "train_generator,\n",
    "samples_per_epoch = nb_train_samples,\n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "nb_val_samples = nb_validation_samples,\n",
    "callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# lets assume `model` is main model \n",
    "model_json = model_final.to_json()\n",
    "with open(\"model_in_json.json\", \"w\") as json_file:\n",
    "    json.dump(model_json, json_file)\n",
    "\n",
    "model_final.save_weights(\"car1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8289fa3934d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# print(history_object.history.keys())\n",
    "# plt.plot(history_object.history['acc'])\n",
    "# plt.plot(history_object.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('acc')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history_object.history['loss'])\n",
    "# plt.plot(history_object.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
